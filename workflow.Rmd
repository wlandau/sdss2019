---
title: "Automated workflow"
output: html_notebook
---

## Creating a plan

```{r setup, include = FALSE}
library(drake)
library(keras)
library(tidyverse)
library(rsample)
library(recipes)
library(yardstick)
```


```{r}
library(drake)
library(keras)
library(tidyverse)
library(rsample)
library(recipes)
library(yardstick)

plan <- drake_plan(
  customer_data = read_csv("customer_churn.csv"),
  train_test_split = initial_split(
    customer_data,
    prop = 0.3
  ),
  train_tbl = training(train_test_split),
  test_tbl = testing(train_test_split),
  rec_obj = train_tbl %>%
    recipe(Churn ~ .) %>%
    step_rm(customerID) %>%
    step_naomit(all_outcomes(), all_predictors()) %>%
    step_discretize(tenure, options = list(cuts = 6)) %>%
    step_log(TotalCharges) %>%
    step_mutate(Churn = ifelse(Churn == "Yes", 1, 0)) %>%
    step_dummy(all_nominal(), -all_outcomes()) %>%
    step_center(all_predictors(), -all_outcomes()) %>%
    step_scale(all_predictors(), -all_outcomes()) %>%
    prep(),
  save_rec_obj = save(rec_obj, file = "rec_obj.RData"),
  x_train_tbl = juice(rec_obj, all_predictors(), composition = "matrix"),
  y_train_vec = juice(rec_obj, all_outcomes()) %>% pull(),
  baked_test = bake(rec_obj, test_tbl),
  x_test_tbl = baked_test %>%
    select(-Churn) %>%
    as.matrix(),
  y_test_vec = baked_test %>%
    select(Churn) %>%
    pull(),
  model_keras = keras_model_sequential() %>%
    layer_dense(
      units = 16,
      kernel_initializer = "uniform",
      activation = "relu",
      input_shape = ncol(x_train_tbl)
    ) %>%
    layer_dropout(rate = 0.1) %>%
    layer_dense(
      units = 16,
      kernel_initializer = "uniform",
      activation = "relu"
    ) %>%
    layer_dropout(rate = 0.1) %>%
    layer_dense(
      units = 1,
      kernel_initializer = "uniform",
      activation = "sigmoid"
    ) %>%
    compile(
      optimizer = "adam",
      loss = "binary_crossentropy",
      metrics = c("accuracy")
    ),
  fit_keras = fit(
    object = model_keras,
    x = x_train_tbl,
    y = y_train_vec,
    batch_size = 50,
    epochs = 35,
    validation_split = 0.30,
    verbose = 0
  ),
  plot_fit_keras = plot(fit_keras),
  yhat_keras_class_vec = model_keras %>%
    predict_classes(x_test_tbl) %>%
    as.factor() %>%
    fct_recode(yes = "1", no = "0"),
  yhat_keras_prob_vec =
    model_keras %>%
      predict_proba(x_test_tbl) %>%
      as.vector(),
  test_truth = y_test_vec %>%
    as.factor() %>%
    fct_recode(yes = "1", no = "0"),
  estimates_keras_tbl = tibble(
    truth = test_truth,
    estimate = yhat_keras_class_vec,
    class_prob = yhat_keras_prob_vec
  ),
  confusion_matrix = estimates_keras_tbl %>%
    conf_mat(truth, estimate),
  save_model = keras:::export_savedmodel.keras.engine.training.Model(model_keras, "newmodel")
)
```

```{r, include = FALSE}
clean(destroy = TRUE)
make(plan, seed = 100)
```

```{r, eval = FALSE}
clean(destroy = TRUE)
make(plan, seed = 100)
```

## Dependency graph

This shows how each step in the workflow is related to each other.

```{r}
config <- drake_config(plan)
vis_drake_graph(config)
```

## Pull data from the plan

```{r}
readd(plot_fit_keras)
```

```{r}
readd(confusion_matrix)
```


